{"cells":[{"cell_type":"markdown","metadata":{"id":"fI1IPtaDv8nw"},"source":["## Measure the Energy Intensity of Running Tabular DDPMs ##\n","\n","Things we care about:\n","1) Model Size\n","2) Model Type (CNN or MLP)\n","3) Dataset size\n","4) Batch Size\n","5) Data Type (Image or Tabular)\n","6) Training time\n","7) Sampling time\n","8) Sampled Data size\n","\n","We hope to use the experiment run with this script to evaluate the carbon intensity of DDPMs\n","\n","Training: Run DDPM training until convergence\n","\n","Sampling: Generate 8192 samples with batch size parameter"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"bp5B00Ckv8n0","executionInfo":{"status":"error","timestamp":1709157912755,"user_tz":300,"elapsed":6341,"user":{"displayName":"Md Ferdous Alam","userId":"11889471720329890493"}},"outputId":"6e7343b8-b6f9-4c91-e186-10c9f3a4c637","colab":{"base_uri":"https://localhost:8080/","height":383}},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'TabDiffusionTools'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d765b0c89946>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mTabDiffusionTools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mTDT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'TabDiffusionTools'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["#import the goods\n","\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import TabDiffusionTools as TDT\n","import time\n","\n","\"\"\"\n","start = time.time()\n","\n","-Run\n","\n","end = time.time()\n","\n","clock = end - start\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lL6PGQCLv8n2","outputId":"6ae965e2-1026-4684-d1bf-7428cab3a17d"},"outputs":[{"name":"stdout","output_type":"stream","text":["(4096, 4, 5)\n","(4096, 20)\n","(4096, 8, 5)\n","(4096, 40)\n"]}],"source":["#Set up the loop:\n","machine_id = 'Quadro_RTX_4000_Shannon'\n","DS_sizes = [1024,2048, 4096]\n","batch_size = 512\n","patience = 512\n","\n","Net_sizes = [[32,32],\n","             [64,64],\n","             [128,128,128,128],\n","             [256,256,256,256]]\n","\n","t_dim = 32\n","\n","\n","# Load in parametric wave data\n","Wave_4 = np.concatenate((np.load('./dataset/Wave_4_Img_64/params.npy'), np.load('./dataset/Wave_4_Img_128/params.npy')), axis = 0)\n","\n","print(Wave_4.shape) # should be (8192,2,5)\n","\n","Wave_4 = Wave_4.reshape((4096,20))\n","print(Wave_4.shape) # should be (8192,10)\n","\n","Wave_8 = np.concatenate((np.load('./dataset/Wave_8_Img_64/params.npy'), np.load('./dataset/Wave_8_Img_128/params.npy')), axis = 0)\n","\n","print(Wave_8.shape) # should be (8192,8,5)\n","\n","\n","Wave_8 = Wave_8.reshape((4096,40))\n","\n","print(Wave_8.shape) # should be (8192,40)\n","\n","Wave = [Wave_4, Wave_8]\n","\n","val_limits = [[0,255],\n","                      [0.5,8],\n","                      [-np.pi,np.pi],\n","                      [-np.pi,np.pi],\n","                      [0,255]]\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YebMEsy2v8n2","outputId":"2aefe4c7-2461-4d9d-d9d5-d7d0f2a3e188"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1024, 20)\n","Step 500/100000 Loss: 0.34430384635925293\n","Step 1000/100000 Loss: 0.2991546094417572\n","Step 1500/100000 Loss: 0.30185145139694214\n","Step 2000/100000 Loss: 0.27196940779685974\n","Step 2500/100000 Loss: 0.31362801790237427\n","Step 3000/100000 Loss: 0.2727885842323303\n","Step 3500/100000 Loss: 0.263915479183197\n","Step 4000/100000 Loss: 0.26723822951316833\n","Step 4500/100000 Loss: 0.27648159861564636\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1352.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.32534095644950867\n","Step 1000/100000 Loss: 0.28966769576072693\n","Step 1500/100000 Loss: 0.2652687132358551\n","Step 2000/100000 Loss: 0.24309611320495605\n","Step 2500/100000 Loss: 0.25609269738197327\n","Step 3000/100000 Loss: 0.2498127520084381\n","Step 3500/100000 Loss: 0.29389163851737976\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1313.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.31188511848449707\n","Step 1000/100000 Loss: 0.29368510842323303\n","Step 1500/100000 Loss: 0.2921791672706604\n","Step 2000/100000 Loss: 0.2560029923915863\n","Step 2500/100000 Loss: 0.23677611351013184\n","Step 3000/100000 Loss: 0.24086351692676544\n","Step 3500/100000 Loss: 0.24155913293361664\n","Step 4000/100000 Loss: 0.2526160478591919\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 846.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.2993670105934143\n","Step 1000/100000 Loss: 0.2581441402435303\n","Step 1500/100000 Loss: 0.25250443816185\n","Step 2000/100000 Loss: 0.23356202244758606\n","Step 2500/100000 Loss: 0.22366057336330414\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 516.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(2048, 20)\n","Step 500/100000 Loss: 0.3099687695503235\n","Step 1000/100000 Loss: 0.30382391810417175\n","Step 1500/100000 Loss: 0.286175400018692\n","Step 2000/100000 Loss: 0.2841852605342865\n","Step 2500/100000 Loss: 0.2561042010784149\n","Step 3000/100000 Loss: 0.28873419761657715\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1088.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.2991623878479004\n","Step 1000/100000 Loss: 0.26538166403770447\n","Step 1500/100000 Loss: 0.2560442388057709\n","Step 2000/100000 Loss: 0.23036514222621918\n","Step 2500/100000 Loss: 0.2448471039533615\n","Step 3000/100000 Loss: 0.23954103887081146\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1352.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.28541603684425354\n","Step 1000/100000 Loss: 0.28362271189689636\n","Step 1500/100000 Loss: 0.24864666163921356\n","Step 2000/100000 Loss: 0.2626688480377197\n","Step 2500/100000 Loss: 0.23699937760829926\n","Step 3000/100000 Loss: 0.250749409198761\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 828.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.26955410838127136\n","Step 1000/100000 Loss: 0.2425990104675293\n","Step 1500/100000 Loss: 0.2525503933429718\n","Step 2000/100000 Loss: 0.2477676421403885\n","Step 2500/100000 Loss: 0.26313745975494385\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 556.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(4096, 20)\n","Step 500/100000 Loss: 0.2633805572986603\n","Step 1000/100000 Loss: 0.2562670409679413\n","Step 1500/100000 Loss: 0.26685652136802673\n","Step 2000/100000 Loss: 0.2642025947570801\n","Step 2500/100000 Loss: 0.2727465331554413\n","Step 3000/100000 Loss: 0.23109273612499237\n","Step 3500/100000 Loss: 0.24420876801013947\n","Step 4000/100000 Loss: 0.22148318588733673\n","Step 4500/100000 Loss: 0.28222379088401794\n","Step 5000/100000 Loss: 0.2767123579978943\n","Step 5500/100000 Loss: 0.2751116454601288\n","Step 6000/100000 Loss: 0.24115724861621857\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1414.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.2606051564216614\n","Step 1000/100000 Loss: 0.2568081319332123\n","Step 1500/100000 Loss: 0.3005150854587555\n","Step 2000/100000 Loss: 0.23964548110961914\n","Step 2500/100000 Loss: 0.28158843517303467\n","Step 3000/100000 Loss: 0.27085551619529724\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1293.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.28668519854545593\n","Step 1000/100000 Loss: 0.24278612434864044\n","Step 1500/100000 Loss: 0.2479548454284668\n","Step 2000/100000 Loss: 0.2391963005065918\n","Step 2500/100000 Loss: 0.23846197128295898\n","Step 3000/100000 Loss: 0.24909625947475433\n","Step 3500/100000 Loss: 0.2569200396537781\n","Step 4000/100000 Loss: 0.25819534063339233\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 836.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.2608659863471985\n","Step 1000/100000 Loss: 0.22584064304828644\n","Step 1500/100000 Loss: 0.2475544661283493\n","Step 2000/100000 Loss: 0.2425980120897293\n","Step 2500/100000 Loss: 0.23901446163654327\n","Step 3000/100000 Loss: 0.2652422785758972\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 542.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(1024, 40)\n","Step 500/100000 Loss: 0.5512741804122925\n","Step 1000/100000 Loss: 0.45049625635147095\n","Step 1500/100000 Loss: 0.46027490496635437\n","Step 2000/100000 Loss: 0.4450562000274658\n","Step 2500/100000 Loss: 0.4144198000431061\n","Step 3000/100000 Loss: 0.43939658999443054\n","Step 3500/100000 Loss: 0.42933255434036255\n","Step 4000/100000 Loss: 0.45160552859306335\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1358.83it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.5213785171508789\n","Step 1000/100000 Loss: 0.44881197810173035\n","Step 1500/100000 Loss: 0.4394035339355469\n","Step 2000/100000 Loss: 0.4304830729961395\n","Step 2500/100000 Loss: 0.448137104511261\n","Step 3000/100000 Loss: 0.4346903860569\n","Step 3500/100000 Loss: 0.44333574175834656\n","Step 4000/100000 Loss: 0.41853925585746765\n","Step 4500/100000 Loss: 0.4328880310058594\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1313.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.5282907485961914\n","Step 1000/100000 Loss: 0.4573584198951721\n","Step 1500/100000 Loss: 0.4273681342601776\n","Step 2000/100000 Loss: 0.4370918273925781\n","Step 2500/100000 Loss: 0.42100176215171814\n","Step 3000/100000 Loss: 0.4501557946205139\n","Step 3500/100000 Loss: 0.4078187048435211\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 918.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.4830249845981598\n","Step 1000/100000 Loss: 0.44522199034690857\n","Step 1500/100000 Loss: 0.43097248673439026\n","Step 2000/100000 Loss: 0.42052149772644043\n","Step 2500/100000 Loss: 0.4175175726413727\n","Step 3000/100000 Loss: 0.4014117419719696\n","Step 3500/100000 Loss: 0.40372753143310547\n","Step 4000/100000 Loss: 0.3917401432991028\n","Step 4500/100000 Loss: 0.4068474769592285\n","Step 5000/100000 Loss: 0.40326452255249023\n","Step 5500/100000 Loss: 0.3897875249385834\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 541.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(2048, 40)\n","Step 500/100000 Loss: 0.4825752377510071\n","Step 1000/100000 Loss: 0.4528622627258301\n","Step 1500/100000 Loss: 0.42448240518569946\n","Step 2000/100000 Loss: 0.3981395363807678\n","Step 2500/100000 Loss: 0.42821741104125977\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1136.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.4634714126586914\n","Step 1000/100000 Loss: 0.4250909984111786\n","Step 1500/100000 Loss: 0.4106253683567047\n","Step 2000/100000 Loss: 0.4239042401313782\n","Step 2500/100000 Loss: 0.41954779624938965\n","Step 3000/100000 Loss: 0.4102029800415039\n","Step 3500/100000 Loss: 0.41948533058166504\n","Step 4000/100000 Loss: 0.412325382232666\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1297.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.4523891508579254\n","Step 1000/100000 Loss: 0.41924983263015747\n","Step 1500/100000 Loss: 0.4267060458660126\n","Step 2000/100000 Loss: 0.40662136673927307\n","Step 2500/100000 Loss: 0.4034392833709717\n","Step 3000/100000 Loss: 0.4222440719604492\n","Step 3500/100000 Loss: 0.4156742990016937\n","Step 4000/100000 Loss: 0.40762463212013245\n","Step 4500/100000 Loss: 0.39260250329971313\n","Step 5000/100000 Loss: 0.39355379343032837\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 759.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.4180328845977783\n","Step 1000/100000 Loss: 0.3950093388557434\n","Step 1500/100000 Loss: 0.417559951543808\n","Step 2000/100000 Loss: 0.410823255777359\n","Step 2500/100000 Loss: 0.3981829285621643\n","Step 3000/100000 Loss: 0.39622074365615845\n","Step 3500/100000 Loss: 0.41500741243362427\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 491.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["(4096, 40)\n","Step 500/100000 Loss: 0.44956302642822266\n","Step 1000/100000 Loss: 0.423252671957016\n","Step 1500/100000 Loss: 0.40099868178367615\n","Step 2000/100000 Loss: 0.41222286224365234\n","Step 2500/100000 Loss: 0.4315783977508545\n","Step 3000/100000 Loss: 0.4134812355041504\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1016.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.4094313085079193\n","Step 1000/100000 Loss: 0.42886725068092346\n","Step 1500/100000 Loss: 0.40520429611206055\n","Step 2000/100000 Loss: 0.43543368577957153\n","Step 2500/100000 Loss: 0.41017743945121765\n","Step 3000/100000 Loss: 0.42282700538635254\n","Step 3500/100000 Loss: 0.4235982894897461\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 1207.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.44135138392448425\n","Step 1000/100000 Loss: 0.4332573413848877\n","Step 1500/100000 Loss: 0.41786810755729675\n","Step 2000/100000 Loss: 0.417950838804245\n","Step 2500/100000 Loss: 0.39552003145217896\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 927.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Step 500/100000 Loss: 0.4296523630619049\n","Step 1000/100000 Loss: 0.4467632472515106\n","Step 1500/100000 Loss: 0.42135390639305115\n","Step 2000/100000 Loss: 0.4151332974433899\n","Step 2500/100000 Loss: 0.39981818199157715\n","Step 3000/100000 Loss: 0.4060977101325989\n","Step 3500/100000 Loss: 0.39773446321487427\n","Step 4000/100000 Loss: 0.3861753046512604\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 127/127 [00:00<00:00, 482.32it/s]\n"]}],"source":["labels = ['run_id', 'model size', 'training epochs', 'train time', 'sample time 8192 samples']\n","Results = []\n","Results.append(labels)\n","\n","\n","for i in range(len(Wave)):\n","    for j in  range(len(DS_sizes)):\n","     # Set up the training data:\n","        DS = Wave[i][0:DS_sizes[j]]\n","        num_waves = int(DS.shape[1]//5)\n","        print(DS.shape)\n","        LIMITS = []\n","        for k in range(DS.shape[1]):\n","            LIMITS.append(val_limits[k%5])\n","        LIMITS = np.array(LIMITS)\n","\n","        for k in range(len(Net_sizes)):\n","            DDPM_Dict = {\n","                        'xdim' : DS.shape[1],\n","                        'X_LL' : LIMITS[:,0],\n","                        'X_UL' : LIMITS[:,1],\n","                        'ydim': 0,\n","                        'cdim': 0,\n","                        'datalength': len(DS),\n","                        'tdim': t_dim,\n","                        'net': Net_sizes[k],\n","                        'batch_size': batch_size,\n","                        'Training_Epochs': 100000,\n","                        'Diffusion_Timesteps': 128,\n","                        'lr' : 0.00025,                 # learning rate\n","                        'weight_decay': 0.0,            # weight decay\n","                        'device_name': 'cuda:0'}        # gpu device name}\n","\n","            # Set up the model\n","\n","            T = TDT.DiffusionEnv(DDPM_Dict,\n","                X=DS)\n","                #Y=Y_set,\n","                #Cons = Con_set,\n","                #dataLength=num_samples,\n","                #lr = 0.00025,\n","                #weight_decay=0.0,\n","                #device=torch.device('cuda:0'))\n","            model_size = 0\n","            for p in T.diffusion.parameters():\n","                model_size += p.numel()\n","\n","            # Train the model\n","            start = time.time()\n","\n","            epochs = T.run_train_loop_patience(batches_per_epoch=100, patience = 1000)\n","\n","            end = time.time()\n","            clock_train = end - start\n","\n","            # Sample the model\n","            start = time.time()\n","            X_gen, unnorm = T.gen_samples(8192)\n","            end = time.time()\n","\n","            clock_sample = end - start\n","            id = 'Tab_Wave_' + str(num_waves) + '_DS_' + str(DS_sizes[j]) + '_Net_' + str(k)\n","            np.save('./generated_samples/Shannon_RTX_4000/' + id + '_Samples_' + machine_id + '.npy', X_gen)\n","\n","            Results.append([id,model_size, epochs, clock_train, clock_sample])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UyxJHJtTv8n3"},"outputs":[],"source":["import csv\n","\n","path = './Tab_Wave_Results_' + machine_id +'.csv'\n","\n","f =  open(path, 'w', newline='')\n","writer = csv.writer(f)\n","writer.writerows(Results)\n","f.close()"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}